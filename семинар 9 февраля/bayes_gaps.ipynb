{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор\n",
    "## Теория в двух словах\n",
    "\n",
    "Вероятность - функция $P()$, определенная на событиях. Значение функции отражает наше представление о том, с какой вероятностью данное событие случается: 0 - не случается вовсе, 1 - случается всегда.\n",
    "\n",
    "Сегодня нам потребуется два стандартных факта, о вероятностях.\n",
    "\n",
    "### Условная вероятность и формула Байеса\n",
    "Наши представления о том, что случится событие $A$, если мы знаем, что $B$ уже произошло традиционно вычисляются по формуле \n",
    "\n",
    "$p(A | B) = \\frac{p(A B)}{p(B)}$. \n",
    "\n",
    "Здесь $p(A B)$ - вероятность того, что случится и А, и B.\n",
    "\n",
    "Поменяем местами A и B в формуле, получим $p(B | A) = p(A B) / p(A)$, домножим обе части на $p(B)$, получится $p(AB) = p(B | A) p(A)$. Подставив это выражение в первую формулу, получаем\n",
    "\n",
    "$ p(A | B) = \\frac{p(B | A) p(A)}{p(B)} $\n",
    "\n",
    "Эта формула называется формулой Байеса. Она позволяет нам скорректировать свое представление о том, вероятности $p(A)$ с учетом произошедшего события $B$.\n",
    "\n",
    "### Независимости событий\n",
    "\n",
    "В теории вероятности пара событий $A$ и $B$ называются независимыми, если выполнено соотношение\n",
    "\n",
    "$p(AB) = p(A)p(B)$.\n",
    "\n",
    "Определение продолжается очевидным образом: $n$ событий $A_1, ..., A_n$ называются независимыми, если выполнено\n",
    "\n",
    "$p(A_1,...,A_n) = p(A_1)...p(A_n)$\n",
    "\n",
    "### Комбинируем знания\n",
    "\n",
    "Допустим, у нас есть обучающий объект $x$ из класса $y \\in \\{0, 1\\}$, у обучающего объекта есть набор признаков $x_1, ..., x_n$.\n",
    "\n",
    "Положим в формуле Байеса в качестве события $A$ событие \"объект принадлежит классу $y$\", а в качестве события $B$ событие \"объект обладает признаками $x_1, ...,x_n$\". Перепишем формулу в более удобных обозначениях:\n",
    "\n",
    "$p(y | x_1, ..., x_n) = \\frac{p(y) p(x_1, ..., x_n | y)}{p(x_1, ..., x_n)} $\n",
    "\n",
    "Дальше мы можем сделать \"наивное\" предоложение о том, что все признакми объекта независимы между собой, зависят только от класса:\n",
    "\n",
    "$p(x_1, ..., x_n | y) = \\prod p(x_i | y) $\n",
    "\n",
    "Это предположение нас приводит к формуле вероятности\n",
    "\n",
    "$p(y | x_1, ..., x_n) = \\frac{p(y) \\prod p(x_i | y)}{p(x_1, ..., x_n)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример\n",
    "## Небольшой спам фильтр своими руками\n",
    "\n",
    "Разберем работу наивного байесовского классификатора на примере. В качестве данных взяли набор sms-сообщений, нужно определить, является ли данное сообщение рекламным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('SMSSpamCollection.txt',\n",
    "                   sep = '\\t',\n",
    "                   names = ('label', 'text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на случайно взятое сообщение. Это спам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.ix[3330].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работать с числами куда проще, нежели со строками. Каждое сообщение мы разобьем на слова, а каждому слову присвоим уникальный номер.\n",
    "\n",
    "Ниже определена функция, разбивающая сообщения на слова (можно ли её улучшить?), а также словарь *mapping*, сопоставляющий каждому слову число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def split_message(message):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \",  message.lower()).split()\n",
    "\n",
    "mapping = CountVectorizer(analyzer=split_message).fit(data.text).vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как всегда, данные мы разобьем на обучающую и тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data[:4000]\n",
    "data_test = data[4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция, которая составляет список (с повторами) всех встречающихся слов в сообщениях типа *sms_type* в *data*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words(data, sms_type):\n",
    "    return data[data.label == sms_type].text.apply(split_message).sum(axis = 0)\n",
    "\n",
    "spam_words = get_words(data_train, 'spam')\n",
    "ham_words = get_words(data_train, 'ham')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А в этой ячейки списки слов преобразуются в списки номеров слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words_to_numbers = lambda message: [mapping[word] for word in message]\n",
    "\n",
    "spam_np = np.array(words_to_numbers(spam_words))\n",
    "ham_np = np.array(words_to_numbers(ham_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последние приготовления перед тем как написать классификатор. В нашем словаре всего $n$ слов, в обучающий выборке *N_spam* слов, встетившихся в рекламных сообщениях, *N_ham* слов, встретившихся в обычных сообщениях.\n",
    "\n",
    "В массиве *spam_unique* хранятся номера слов, встретившихся в рекламных сообщениях, а массив *spam_counts* содержит данных о том, сколько раз каждое слово встретилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(mapping)\n",
    "N_spam = len(spam_np)\n",
    "N_ham = len(ham_np)\n",
    "\n",
    "spam_unique, spam_counts = np.unique(spam_np, return_counts = True)\n",
    "ham_unique, ham_counts = np.unique(ham_np, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Слово под номером %d встретилось в рекламных сообщениях %d раз.' % (spam_unique[3], spam_counts[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте вычислим вероятности, необходимые для работы классификатора.\n",
    "\n",
    "Для каждого слова $x_i$ вероятность того, что оно принадлежит классу $y$ (спам или не спам) определяется формулой\n",
    "\n",
    "$$ p(x_i | y) = \\frac{N_{iy} + \\alpha}{N_y + \\alpha n} $$\n",
    "\n",
    "Здесь $N_{iy}$ равно количеству раз, которое слово $i$ встретилось в сообщениях класса $y$ обучающей выборки, а $N_y$ равно количеству слов в классе $y$ в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь можно написать и сам классификатор. Он вычисляет значение $p(y) \\prod p(x_i | y)$ для двух значений классов, и выбирает тот класс $y$, для которого это значение больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В какой доле случаев класс предсказан правильно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data_test.label == data_test.text.apply(classify)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как часто спам оказывается помечен как обычное сообщение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(((data_test.label == 'spam') &\n",
    "  (data_test.text.apply(classify) == 'ham')).mean() / \n",
    "     (data_test.label == 'spam').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как часто обычное сообщение оказывается помечено как спам?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(((data_test.label == 'ham') & \n",
    "  (data_test.text.apply(classify) == 'spam')).mean() /\n",
    "    (data_test.label == 'ham').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на работу классификатора поближе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "ix = np.random.randint(0, data.shape[0])\n",
    "example = data.text[ix]\n",
    "\n",
    "print('Test message: %s \\nclass:\\t%s \\nprediction: %s' % (example, data.label[ix], classify(example)))\n",
    "words = split_message(example)[0:15]\n",
    "numbers = words_to_numbers(words)\n",
    "\n",
    "x = np.arange(len(words)) + 1\n",
    "y_1 = p_spam[numbers]\n",
    "y_2 = p_ham[numbers]\n",
    "\n",
    "w_1 = np.prod(y_1) / (np.prod(y_1) + np.prod(y_2))\n",
    "w_2 = np.prod(y_2) / (np.prod(y_1) + np.prod(y_2))\n",
    "\n",
    "ax.plot(x, y_1, 'ro', lw = 2, label = ('spam, $w_{spam}$ = %f' % w_1))\n",
    "ax.plot(x, y_2, 'bo', lw = 2, label = ('ham, $w_{ham}$ = %f' % w_2))\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(words, fontsize=14)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
