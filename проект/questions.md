# Список вопросов к проектному заданию.

Полные данные и подробное описание задачи можно найти [здесь](https://www.kaggle.com/c/job-salary-prediction)

1. Признаки какого вида встречаются в данных?

 *Открыть данные с помощью pandas и посмотреть на первые несколько строк таблицы.*

2. Найти самые популярные и редкие слова в тексте (здесь и далее речь идет о поле FullDescription). Объяснить почему именно эти слова встречаются так часто или так редко.

 *Прочитать про класс sklearn.feature_extraction.text.CountVectorizer, его методы fit и transform. Понять как кодирующей матрице получить частоты слов.*

3. Построить распределение целевой переменной. Посчитать её среднее значение, медиану, дисперсию. Как выглядят объявления, в которых предлагается очень маленькая и очень большая зарплата? При выполнении задания полезным может оказаться метод pandas.DataFrame.quantile.

 *Освежить в памяти занятия по pandas. Плотность можно построить с помощью метода pandas.DataFrame.hist, остальные функции не составит труда найти.*

4. Предлагаемый авторами задания критерий качества - среднее абсолютное отклонение предсказания. Вычислить значение ошибки предсказания, если в качестве предсказания будет использоваться среднее значение зарплаты.

 *Подумайте, может ли какое-то другое число давать меньшее значение ошибки?*

5. Найти слова, которые часто встречаются рядом: пары, тройки. Можно ли как-то объяснить их соседство?

 *Продолжить знакомство с классом sklearn.feature_extraction.text.CountVectorizer, обратить внимание на параметр ngram_range.*

6. Для нескольких слов постройте распределение числа их вхождений в текст. Каким известным распределением можно описать получившуюся зависимость.

 *Некоторые слова встречаются в текстах редко. Можно попробовать строить распределение на основе только тех текстов, в которых встречается данное слово. Здесь может помочь функция numpy.nonzero().*

7. Обучить на данных простую модель линейной регрессии.

    - Попробовать три метода вложения текстов: CountVectorizer, tf и tf-idf.

    - Попробовать несколько стратегий регуляризации, подобрать параметры регуляризации.
 
    - Исследовать иные возможности настройки параметров этих методов.
 
    - Измерить качество обученной линейной модели.

8. Выбрать самые информативные признаки с помощью одной из обученных линейных моделей. Для этого достаточно найти слова, соответствующие самым большим весам регрессии. Что это за слова? Почему у них большой вес?

9. Ввести в данные несколько дополнительных признаков объектов, которые были бы способны улучшить качество предсказания. Это может быть информация о регионе, в котором предложена вакансия, это может быть категория вакансии. Обучить линейную модель с новыми дополнительными признаками.

10. Обучить на данных [случайный лес](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html). 

    - Попробовать три метода вложения текстов: CountVectorizer, tf и tf-idf.
    
    - Подобрать максимальную глубину деревьев для деревьев леса; использовать не менее 10 деревьев, их число можно также попробовать подобрать
 
    - Измерить качество обученной модели.
    
 * Для воспроизводимости результатов можно зафиксировать случайное состояние random_state, из которого начинает работу алгоритм *

11. Выбрать самые информативные признаки случайного леса с помощью его атрибута *feature_importances_*. Каким словам они соответствуют? Отличаются ли они от информативных признаков линейной модели?

12. *(Дополнительно)* Обучить какую-либо модель на полном наборе данных. Сравнить свои результаты с результатами на [Kaggle](https://www.kaggle.com/c/job-salary-prediction).

  * Обратите внимание, что в оригинальном конкурсе для оценки качества используется среднее абсолютное отклонение от предсказания *